# Курсы

## Курсы, которые надо пройти

* [Deep Learning Google](https://eu.udacity.com/course/deep-learning--ud730)
* [Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)
* [Learning TensorFlow](https://learningtensorflow.com)
* [Kaggel Learn](https://www.kaggle.com/learn/overview)
* [Data Vizualization Kaggle](https://www.kaggle.com/learn/data-visualisation)
* Andrew Ng
* cs221 
* Future Learning 
* [HSE Course (GitHub)](https://github.com/esokolov/ml-course-hse/)
* [Microsoft Professional Program for Artificial Intelligence](https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/)


## Stepic Additional
* [Examination](https://stepik.org/lesson/68008/step/1?unit=44971)
* [Adaptive tasks](https://stepik.org/lesson/43732/step/1?adaptive=true&unit=22777)


## Курсы, что я прохожу

* ODS ML Course Open
* Deep NLP MIPT
* cs224n (NLP) 

## Курсы, что я уже прошел

-----



# Чтение

## Штуки, что надо прочитать 

* [How Numba and Cython speed up Python code](https://rushter.com/blog/numba-cython-python-optimization/)
* [Serving machine learning models with RestServe on R](http://restrserve.org/serving-ml.html)
* [R TensorFlow Tutorial](https://tensorflow.rstudio.com)
* [R Keras Tutorial](https://keras.rstudio.com)
* [New Resources for Deep Learning with the Neuromation Platform](https://medium.com/neuromation-io-blog/new-resources-for-deep-learning-with-the-neuromation-platform-55fd411cb440)
* [Word2Vec Tutorial](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
* [Серия статей про ембединги текста](http://ruder.io/word-embeddings-1/)
* [ImageNet Classification with Deep Convolutional Neural Networks - Colyer](https://blog.acolyer.org/2016/04/20/imagenet-classification-with-deep-convolutional-neural-networks/)
* [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](https://blog.acolyer.org/2016/04/19/context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition/)
* https://habrahabr.ru/post/352632/ Истинная реализация нейросети с нуля. 
* [Functional Programming for Deep Learning](https://www.notion.so/metya/5f25295584414592a3581836625b77d3#d5f53eac3e7146eeba6bf6365449600a)
* Все отсюда! Прекрасный блог про понимание базовых дип лернингов [colah.github.io](http://colah.github.io/archive.html)
* Например вот это - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Manning And Le Cun talks about Innate Prior Chomsky](http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html) 
* http://karpathy.github.io/2015/05/21/rnn-effectiveness/
* [Ассоциативные правила, или пиво с подгузниками](https://habrahabr.ru/company/ods/blog/353502/)
* [Connection between absract algebra and high school algebra](https://blogs.ams.org/matheducation/2015/12/10/connections-between-abstract-algebra-and-high-school-algebra-a-few-connections-worth-exploring/)
* [Instance Embedding: Segmentation Without Proposals](https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1)


## Штуки, что я прочитал

* [Про преобразование фурье](https://habrahabr.ru/post/196374/)
* [Как предсказывают погоду](https://vas3k.ru/blog/how_to_weather/)
* [Генерация стихов нейросетями](https://vas3k.ru/blog/394/)
* [Blockchain]()
* [Ehtereum](https://vas3k.ru/blog/ethereum/)
* [Автоэнкодеры в Keras](https://habrahabr.ru/post/331382/)
* 
-----

## Штуки, что я написал, перевел

* 


# Видео



## Видео, что мне надо посмотреть

* [Essense of Linear Azlgebra](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
* [PyData Meetup (TensorFlow Architecture)](https://www.youtube.com/watch?v=aoin1nl_eSA&feature=youtu.be&t=5810) [Materials](https://github.com/yurijvolkov/pydata_examples)
* [Kaggle Mercedes Benz: предсказание времени тестирования автомобилей ](https://www.youtube.com/watch?v=HT3QpRp2ewA)
* [Эффективные модели ближайших соседей](https://www.youtube.com/watch?v=UUm4MOyVTnE)
* [Lisa Feldman: Emotions and brain](https://www.youtube.com/watch?v=h7Mtwds0wW4&feature=youtu.be)
* [Manning And Le Cun talks about Innate Prior Chomsky](https://youtu.be/fKk9KhGRBdI)
* [Attention is all you need by Ilya Polosuhin](https://www.youtube.com/watch?v=I0nX4HDmXKc)
* [Simon says LSTM](https://www.youtube.com/watch?v=wYI7RZz4Rz0)

## Видео, что я посмотрел 

* [NLP натекин](https://www.youtube.com/watch?v=Ozm0bEi5KaI)
* [Bias in an Artificial Neural Network explained | How bias impacts training](https://www.youtube.com/watch?v=HetFihsXSys)
* [Keras init bias](https://www.youtube.com/watch?v=zralyi2Ft20)
* [Генератор текста цепями маркова](https://tproger.ru/translations/markov-chains/)
* [Ethereum work like](https://www.youtube.com/watch?v=a-Azm3nEuUI)

