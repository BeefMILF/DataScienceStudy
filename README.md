# My activity to study and do Data Science
То что я сейчас прохожу, читаю, прочитал, посмотрел, сделал и вообще мой личный списочек всего с этим связанного

_Надо из этого сделать вот это https://wiki.nikitavoloboev.xyz/_


# Содержание
<!-- MarkdownTOC bullets="-,+,*" uri_encoding="false" autolink="true" autoanchor="true" -->

- [Курсы и активности](#Курсы-и-активности)
    + [Курсы, что я уже прошел](#Курсы-что-я-уже-прошел)
    + [Курсы, что я прохожу](#Курсы-что-я-прохожу)
    + [Курсы, которые надо пройти](#Курсы-которые-надо-пройти)
    + [Stepic Additional](#stepic-additional)
    + [Где я участвовал как слушатель или как участник или как организатор. Школы, конференции, семинары](#Где-я-участвовал-как-слушатель-или-как-участник-или-как-организатор-Школы-конференции-семинары)
    + [Хакатоны](#Хакатоны)
- [Чтение и писанина](#Чтение-и-писанина)
    + [Штуки, что надо прочитать](#Штуки-что-надо-прочитать)
    + [Штуки, что я прочитал](#Штуки-что-я-прочитал)
    + [Штуки, что я написал, перевел](#Штуки-что-я-написал-перевел)
- [Видео](#Видео)
    + [Видео, что мне надо посмотреть](#Видео-что-мне-надо-посмотреть)
    + [Видео, что я посмотрел](#Видео-что-я-посмотрел)
    + [Подкасты, что я послушал](#Подкасты-что-я-послушал)
- [Наука, работа и проекты](#Наука-работа-и-проекты)
    + [Научные статьи, что я прочитал](#Научные-статьи-что-я-прочитал)
- [My Local Not So Awesome List](#my-local-not-so-awesome-list)
    + [Interested Links](#interested-links)
    + [Necessary and Useful Tools](#necessary-and-useful-tools)
    + [Datasets](#datasets)

<!-- /MarkdownTOC -->

-------
<a id="Курсы-и-активности"></a>
# Курсы и активности

<a id="Курсы-что-я-уже-прошел"></a>
## Курсы, что я уже прошел
* [Летняя Школа. Мастерская Deep Learning](http://letnyayashkola.org/deeplearning/)
* DataCamp:
    * [Intro to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science)
    * [Intermediate Python for Data Science](https://www.datacamp.com/courses/intermediate-python-for-data-science)
    * [Intro to SQL for Data Science](https://www.datacamp.com/courses/intro-to-sql-for-data-science)
    * [Joining Data in PostgreSQL](https://www.datacamp.com/courses/joining-data-in-postgresql)
* Stepic:
    * Теорвер
    * Матстат
    * Дискретка

<a id="Курсы-что-я-прохожу"></a>
## Курсы, что я прохожу

* [Deep Learning на пальцах!](dlcourse.ai)
* ODS ML Course Open
* Deep NLP MIPT
* cs224n (NLP) 
* cs231n (DeepLearning)
* [Carnegie Melon Deep Learning Course](http://deeplearning.cs.cmu.edu) 


<a id="Курсы-которые-надо-пройти"></a>
## Курсы, которые надо пройти 

* [Deep Learning Google](https://eu.udacity.com/course/deep-learning--ud730)
* [Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)
* [Learning TensorFlow](https://learningtensorflow.com)
* [Kaggel Learn](https://www.kaggle.com/learn/overview)
* [Data Vizualization Kaggle](https://www.kaggle.com/learn/data-visualisation)
* Andrew Ng
* cs221 
* Future Learning 
* [HSE Course (GitHub)](https://github.com/esokolov/ml-course-hse/)
* [Microsoft Professional Program for Artificial Intelligence](https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/)
* [Blommberg ML](https://bloomberg.github.io/foml/#home)
* [Toronto DL](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/)
* [Elements of AI](https://course.elementsofai.com)
* [Julia Scientific Programming Coursera](https://ru.coursera.org/learn/julia-programming)
* [Stepic Julia](https://stepik.org/course/2407)


<a id="stepic-additional"></a>
## Stepic Additional

* [Examination](https://stepik.org/lesson/68008/step/1?unit=44971)
* [Adaptive tasks](https://stepik.org/lesson/43732/step/1?adaptive=true&unit=22777)



<a id="Где-я-участвовал-как-слушатель-или-как-участник-или-как-организатор-Школы-конференции-семинары"></a>
## Где я участвовал как слушатель или как участник или как организатор. Школы, конференции, семинары

* [Летняя Школа. Мастерская Deep Learning](http://letnyayashkola.org/deeplearning/)
* [Data Fest^5, Москва,28 апреля 2018](http://datafest.ru/5/)

<a id="Хакатоны"></a>
## Хакатоны
* [4spb: Машинное обучение для гражданских проектов](https://opendata.te-st.ru/) ([являюсь победителем](https://te-st.ru/reports/4spb-results/) 
* [AI Hack Spb 2017](https://science-guide.timepad.ru/event/440300/), [vk](https://vk.com/aihackathon?w=address-139088047)

-----



<a id="Чтение-и-писанина"></a>
# Чтение и писанина

<a id="Штуки-что-надо-прочитать"></a>
## Штуки, что надо прочитать 

* [How Numba and Cython speed up Python code](https://rushter.com/blog/numba-cython-python-optimization/)
* [Serving machine learning models with RestServe on R](http://restrserve.org/serving-ml.html)
* [R TensorFlow Tutorial](https://tensorflow.rstudio.com)
* [R Keras Tutorial](https://keras.rstudio.com)
* [New Resources for Deep Learning with the Neuromation Platform](https://medium.com/neuromation-io-blog/new-resources-for-deep-learning-with-the-neuromation-platform-55fd411cb440)
* [Word2Vec Tutorial](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
* [Серия статей про ембединги текста](http://ruder.io/word-embeddings-1/)
* [ImageNet Classification with Deep Convolutional Neural Networks - Colyer](https://blog.acolyer.org/2016/04/20/imagenet-classification-with-deep-convolutional-neural-networks/)
* [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](https://blog.acolyer.org/2016/04/19/context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition/)
* [Истинная реализация нейросети с нуля. Часть 2](https://habrahabr.ru/post/352632/) 
* [Functional Programming for Deep Learning](https://www.notion.so/metya/5f25295584414592a3581836625b77d3#d5f53eac3e7146eeba6bf6365449600a)
* Все отсюда! Прекрасный блог про понимание базовых дип лернингов [colah.github.io](http://colah.github.io/archive.html)
* Например вот это - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Manning And Le Cun talks about Innate Prior Chomsky](http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html) 
* [The Unreasonable Effectiveness of Recurrent Neural Networks (Карпатый)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [Ассоциативные правила, или пиво с подгузниками](https://habrahabr.ru/company/ods/blog/353502/)
* [Connection between absract algebra and high school algebra](https://blogs.ams.org/matheducation/2015/12/10/connections-between-abstract-algebra-and-high-school-algebra-a-few-connections-worth-exploring/)
* [Instance Embedding: Segmentation Without Proposals](https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1)
* [Обзор топологий глубоких сверточных сетей](https://habrahabr.ru/company/mailru/blog/311706/)
* [Generative Adversarial Nets and Variational Autoencoders at ICML 2018](https://medium.com/peltarion/generative-adversarial-nets-and-variational-autoencoders-at-icml-2018-6878416ebf22)
* [Hybrid optical-electronic convolutional neural networks with optimized diffractive optics for image classification](https://www.nature.com/articles/s41598-018-30619-y)
* [CERN Project Sees Orders-of-Magnitude Speedup with AI Approach](https://www.hpcwire.com/2018/08/14/cern-incorporates-ai-into-physics-based-simulations/)
* [***Large-Scale Study of Curiosity-Driven Learning.***](https://pathak22.github.io/large-scale-curiosity/)
* [Building a text classification model with TensorFlow Hub and Estimators](https://medium.com/tensorflow/building-a-text-classification-model-with-tensorflow-hub-and-estimators-3169e7aa568)
* [Moving Beyond Translation with the Universal Transformer.](https://ai.googleblog.com/2018/08/moving-beyond-translation-with.html)
* [Explaining Black-Box Machine Learning Models - Code Part 1: tabular data + caret + iml](https://shirinsplayground.netlify.com/2018/07/explaining_ml_models_code_caret_iml/)
* [Keras DNN Part 2](https://shirinsplayground.netlify.com/2018/06/keras_fruits_lime/)
* [Boosting Part 3](https://shirinsplayground.netlify.com/2018/07/explaining_ml_models_code_text_lime/)
* [Recent Advances for a Better Understanding of Deep Learning − Part I](https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914)
* [What is a Generative Adversarial Network? ](http://hunterheidenreich.com/blog/what-is-a-gan/)
* [Think Julia: How to Think Like a Computer Scientist](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html)
* [Rules of Machine Learning: Best Practices for ML Engineering (24 страницы)](https://drive.google.com/file/d/0B1WwFMq7KtPudkJMNUc2N1FOMzQ/view)
* [A Few Useful Things to Know about Machine Learning (9 страниц)](https://drive.google.com/file/d/0B1WwFMq7KtPuMDA5QU01Tm1TSmM/view)
* [Machine Learning’s ‘Amazing’ Ability to Predict Chaos](https://www.quantamagazine.org/machine-learnings-amazing-ability-to-predict-chaos-20180418/)
* [Markov Chains for Dummies](https://arxiv.org/pdf/1808.08490.pdf)
* [Deep Learning for NLP: An Overview of Recent Trends. 2018](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)
* [habr - Введение в состязательные сети](https://habr.com/company/otus/blog/358946/)
* [habr -Kaggle: Amazon from Space — трюки и хаки при обучении нейросетей](https://habr.com/company/ods/blog/413667/)
* [habr - kaggle: IEEE's Camera Model Identification](https://habr.com/company/ods/blog/415571/)
* [harb Офлайн А/Б тестирование в ритейле](https://habr.com/company/ods/blog/416101/)
* [habr 3-е место в отборочном этапе DataScienceGame 2018](https://habr.com/company/ods/blog/416817/)
* [RL habr Как казаки retro контест решали](https://habr.com/company/ods/blog/421585/)
* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
* [The Annotated Encoder Decoder with Attention](https://bastings.github.io/annotated_encoder_decoder/)
* [How to train your ResNet5, search optimal hyperparameters](https://www.myrtle.ai/2018/09/24/how-to-train-your-resnet-5/)
* [Transfer Learning in NLP (nlp-imagenet-ruder)](http://ruder.io/nlp-imagenet/)
* [Differentiable Image Parameterizations](https://distill.pub/2018/differentiable-parameterizations/)
* [Every fucking post here](https://arogozhnikov.github.io)

<a id="Штуки-что-я-прочитал"></a>
## Штуки, что я прочитал

* [Про преобразование фурье](https://habrahabr.ru/post/196374/)
* [Как предсказывают погоду](https://vas3k.ru/blog/how_to_weather/)
* [Генерация стихов нейросетями](https://vas3k.ru/blog/394/)
* [Ehtereum](https://vas3k.ru/blog/ethereum/)
* [Автоэнкодеры в Keras](https://habrahabr.ru/post/331382/)
* [Разброс и смещение Дяконова](https://alexanderdyakonov.wordpress.com/2018/04/25/%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D0%B5-bias-%D0%B8-%D1%80%D0%B0%D0%B7%D0%B1%D1%80%D0%BE%D1%81-variance-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82/)
* [Распонзнавание сцен и достопримечательностей](https://habr.com/company/jugru/blog/419501/)
* [Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples](https://blog.acolyer.org/2018/08/15/obfuscated-gradients-give-a-false-sense-of-security-circumventing-defenses-to-adversarial-examples/)
* [When DNNs go wrong – adversarial examples and what we can learn from them](https://blog.acolyer.org/2017/02/28/when-dnns-go-wrong-adversarial-examples-and-what-we-can-learn-from-them/)
* [Understanding, generalisation, and transfer learning in deep neural networks](https://blog.acolyer.org/2017/02/27/understanding-generalisation-and-transfer-learning-in-deep-neural-networks/)
* [Universal adversarial perturbations](https://blog.acolyer.org/2017/09/12/universal-adversarial-perturbations/)
* [Delayed impact of fair machine learning](https://blog.acolyer.org/2018/08/13/delayed-impact-of-fair-machine-learning/)
* [Почему хватит считать нейронные сети черным ящиком?](https://habr.com/post/420381/)
* [Ultimate guide to handle Big Datasets for Machine Learning using Dask (in Python)](https://www.analyticsvidhya.com/blog/2018/08/dask-big-datasets-machine_learning-python/)
* [OpenCV People Counter](https://www.pyimagesearch.com/2018/08/13/opencv-people-counter/)
* [Ложь, наглая ложь и причинный вывод (causal inference)](https://ailev.livejournal.com/1435703.html)
* [pandas on ray early lessons](https://rise.cs.berkeley.edu/blog/pandas-on-ray-early-lessons/)
* [Red Flags In DS interview](http://hookedondata.org/Red-Flags-in-Data-Science-Interviews/)
* [Classifying physical activity from smartphone data (Keras and R)](http://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection/)
* [Keras for R](http://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r/)
* [Simple audio classification in keras in R](http://blogs.rstudio.com/tensorflow/posts/2018-06-06-simple-audio-classification-keras/) 
* [Пицца аля-semi-supervised](https://habr.com/company/ods/blog/422873/)
* [Определение цвета автомобилей с использованием нейронных сетей и TensorFlow](https://habr.com/company/intel/blog/422689/)
* [Yes, you should understand backprop. A. Karpaty](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)
* [https://arxiv.org/pdf/1808.06492.pdf](https://arxiv.org/pdf/1808.06492.pdf)
* [Pandas Tips and Tricks](https://towardsdatascience.com/pandas-tips-and-tricks-33bcc8a40bb9)
* [Handling cat Pandas](https://www.datacamp.com/community/tutorials/categorical-data)
* [Using categorical data in machine learning with python Part 1](https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512)
* [Guide to Encoding Categorical Data](http://pbpython.com/categorical-encoding.html)
* [BEYOND ONE-HOT: AN EXPLORATION OF CATEGORICAL VARIABLES](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)
* [Using categorical data in machine learning with python: from dummy variables to Deep category embedding and Cat2vec -Part 2](https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-42fd0a43b009)
* [Python Pandas Tricks](https://realpython.com/python-pandas-tricks/)
* [My New Workflow with Julia 1.0](https://medium.com/@Jernfrost/my-new-workflow-with-julia-1-0-99711103d97c)
* [autokeras kill google automl](https://towardsdatascience.com/autokeras-the-killer-of-googles-automl-9e84c552a319)
* [Serverless tensorflow на AWS Lambda](https://habr.com/company/ods/blog/343538/)
* [Levenberg-Marquardt Optimization (Part 1)](https://medium.com/@sarvagya.vaish/levenberg-marquardt-optimization-part-1-981f5777b1d7)
* [Методы оптимизации нейронных сетей](https://habr.com/post/318970/)
* [DeepHD](https://habr.com/company/yandex/blog/422561/)
* [Kaggle Mercedes и кросс-валидация](https://habr.com/company/ods/blog/336168/)
* [Introduction to Chainer Presentation](https://www.slideshare.net/pfi/introduction-to-chainer-11-may2018-96768990)
* [Визуализация сверточных слоев с помощью Pytorch](https://habr.com/ru/post/436838/)
* [Running Jupyter Lab as a Desktop Application](http://christopherroach.com/articles/jupyterlab-desktop-app/)
* [AlphaStar — новая система искусственного интеллекта для StarCraft II от DeepMind (полный перевод)](https://habr.com/ru/post/437486/)
* [https://habr.com/ru/post/437796/](https://habr.com/ru/post/437796/)
* [Как мы создали рекомендательный сервис по подбору одежды на нейронных сетях](https://habr.com/ru/post/438542/)
* [IPython interactive control](https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6)
* [Approach pretended deep learning models with caution](https://medium.com/comet-ml/approach-pre-trained-deep-learning-models-with-caution-9f0ff739010c)
* 


---

<a id="Штуки-что-я-написал-перевел"></a>
## Штуки, что я написал, перевел

* [Применяем Deep Watershed Transform в соревновании Kaggle Data Science Bowl 2018](https://habrahabr.ru/post/354040/)
* [Из спутниковых снимков в графы (cоревнование SpaceNet Road Detector) — попадание топ-10 и код ](https://habrahabr.ru/post/349068/)
* [Соревнование Pri-matrix Factorization на DrivenData с 1ТБ данных — как мы заняли 3 место](https://habrahabr.ru/post/348540/)

------
<a id="Видео"></a>
# Видео

<a id="Видео-что-мне-надо-посмотреть"></a>
## Видео, что мне надо посмотреть

* [Essense of Linear Azlgebra](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
* [PyData Meetup (TensorFlow Architecture)](https://www.youtube.com/watch?v=aoin1nl_eSA&feature=youtu.be&t=5810) [Materials](https://github.com/yurijvolkov/pydata_examples)
* [Kaggle Mercedes Benz: предсказание времени тестирования автомобилей ](https://www.youtube.com/watch?v=HT3QpRp2ewA)
* [Эффективные модели ближайших соседей](https://www.youtube.com/watch?v=UUm4MOyVTnE)
* [Lisa Feldman: Emotions and brain](https://www.youtube.com/watch?v=h7Mtwds0wW4&feature=youtu.be)
* [Manning And Le Cun talks about Innate Prior Chomsky](https://youtu.be/fKk9KhGRBdI)
* [Attention is all you need by Ilya Polosuhin](https://www.youtube.com/watch?v=I0nX4HDmXKc)
* [Simon says LSTM](https://www.youtube.com/watch?v=wYI7RZz4Rz0)
* [Интервью с Виктором Рогуленко](http://youtube.com/watch?v=ymSqI0hVj-Q)
* [Карты кохонена](https://www.youtube.com/watch?v=5FiH88Rs8Hc&list=PLDCR37g8W9nFO5bPnL91WF28V5L9F-lJL&index=5)

<a id="Видео-что-я-посмотрел"></a>
## Видео, что я посмотрел 

* [NLP натекин](https://www.youtube.com/watch?v=Ozm0bEi5KaI)
* [Bias in an Artificial Neural Network explained | How bias impacts training](https://www.youtube.com/watch?v=HetFihsXSys)
* [Keras init bias](https://www.youtube.com/watch?v=zralyi2Ft20)
* [Генератор текста цепями маркова](https://tproger.ru/translations/markov-chains/)
* [Ethereum work like](https://www.youtube.com/watch?v=a-Azm3nEuUI)
* [Dstl Safe Passage: детекция и классификация траспортных средств — Владимир Игловиков](https://www.youtube.com/watch?v=NV9LSUIVkWA&feature=youtu.be&t=1247)
* [Анализ больших данных в физике элементарных частиц](https://www.youtube.com/watch?v=SgI8S8ltBKc&feature=youtu.be)
* [Large-Scale Study of Curiosity-Driven Learning](https://youtu.be/l1FqtAHfJLI)
* [Подтипирование в Julia: рациональная реконструкция](https://www.youtube.com/watch?v=nnOJfPIrFdM)
* [Semantic Folding: a new model for intelligent text processing](https://www.youtube.com/watch?v=HLuRQKzYbb8&feature=youtu.be)
* [Применение карты Кохонена для классификации](https://www.youtube.com/watch?v=5FiH88Rs8Hc)
* [Lambda Calculus](https://youtu.be/eis11j_iGMs)
* [Essentials: Functional Programming's Y Combinator](https://www.youtube.com/watch?v=9T8A89jgeTI)
* [Illustrated Guide to Recurrent Neural Networks](https://youtu.be/LHXXI4-IEns)
* [illustrated guide to LSTM's and GRU's](https://www.youtube.com/watch?v=8HyCNIVRbSU)
* [Visual Rhythm Beat](https://www.youtube.com/watch?v=K3z68mOLbNo&feature=youtu.be)
* [Deep Learning, Structure and Innate Priors](https://youtu.be/fKk9KhGRBdI)
* [чатботы на дваче с разными алгами внутри](https://youtu.be/1LcdA0Y7IEk)
* 

-----
<a id="Подкасты-что-я-послушал"></a>
## Подкасты, что я послушал
* [Deep Learning и Artificial Intelligence — Episode 0114](http://devzen.ru/episode-0114/) 
* [AI и TensorFlow — Episode 0122](http://devzen.ru/episode-0122/)
* [DataDog и Cloud Spanner](http://devzen.ru/episode-0130/)

------
<a id="Наука-работа-и-проекты"></a>
# Наука, работа и проекты

<a id="Научные-статьи-что-я-прочитал"></a>
## Научные статьи, что я прочитал
* [Deep Learning Based Solar Flare Forecasting Model. I. Results for Line-of-sight Magnetograms et al 2018](http://iopscience.iop.org/article/10.3847/1538-4357/aaae00)
* [No Multiplication? No Floating Point? No Problem! Training Networks for Efficient Inference](https://arxiv.org/abs/1809.09244)
* [Identification of photospheric activity features from SOHO/MDI data using the ASAP tool](https://arxiv.org/abs/1505.02036)
* Identification of photospheric activity features from SOHO/MDI data using the ASAP tool Sol. Phys., 248, 277–296, 2008. DOI: 10.1007/s11207-007-9094-3
* Colak, T., and R. Qahwaji. Automated Solar Activity Prediction: A hybrid computer platform using machine learning and solar imaging for automated prediction of solar flares. Space Weather, 7, S06001, 2009. DOI: 10.1029/2008SW000401
* [Byte-Pair-Encoding et al 2015 senrich](https://arxiv.org/pdf/1508.07909.pdf)

------

<a id="my-local-not-so-awesome-list"></a>
# My Local Not So Awesome List

<a id="interested-links"></a>
## Interested Links

* Отличный туториал модулу датасет в торче [PyTorch Custom Dataset Examples](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)
* слайды доклада по рекомендационной системе нетфликса
[Recommender Systems (Machine Learning Summer School 2014 @ CMU)](http://www.slideshare.net/xamat/recommender-systems-machine-learning-summer-school-2014-cmu)
* [An Interactive Tutorial on Numerical Optimization](http://www.benfrederickson.com/numerical-optimization/)
* [Презентация про видеоанализ с RNN](https://www.slideshare.net/xavigiro/video-analysis-with-recurrent-neural-networks-master-computer-vision-barcelona-2017)
* [The Building Blocks of Interpretability Neural Networks](https://distill.pub/2018/building-blocks/)
* Хаскель и ДипЛернинг - [Awesome Haskell Deep Learning](https://github.com/austinvhuang/awesome-haskell-deep-learning)
* Статья рассуждение [Functional programming for deep-learning](https://towardsdatascience.com/functional-programming-for-deep-learning-bc7b80e347e9) (**clojure**)
* Очерендной осом хаскель мл лист [Awesome haskell ML](https://github.com/DataHaskell/awesome-haskell-ml)
* Раздел дата саенс осом хаскель листа [Awesome Haskell#Data Science](https://github.com/krispo/awesome-haskell#data-science)
* Сайт Data Haskell коммьюнити http://www.datahaskell.org/
* Сайт книги [Over 130 Practical Recipes For Data Analysis and Machine Learning](http://haskelldata.com/) и [репа книги](https://github.com/BinRoot/Haskell-Data-Analysis-Cookbook)
* Кажется главный пакет по хаскель мл (и уже устарел) - [Hlearn](https://github.com/mikeizbicki/HLearn)
* Очередной язычок Nim очередной диплернинг [Experimental rewrite of mnielson's deep learning example code in Nim](https://github.com/jfhg/nimdeep)
* Дичайший диплернинг фреймворк для Nim - [Arraymancer](https://github.com/mratsim/Arraymancer)
* Все что нужно  и всякие другие штуки в МЛ и ДЛ в Джулии (ванлав кажется язычок) в годном месте на [сайте](https://juliaml.github.io) и их [репа](https://github.com/JuliaML)
* [Awesome NLP](https://github.com/keon/awesome-nlp)
* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)
* [Awesome Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)
* [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience)
* [Awesome Machine Learning & Deep Learning Tutorials](https://github.com/ujjwalkarn/Machine-Learning-Tutorials)
* [Awesome R](https://github.com/qinwf/awesome-R)
* [A curated list of data science blogs](https://github.com/rushter/data-science-blogs)
* [Awesome Artificial Intelligence](https://github.com/owainlewis/awesome-artificial-intelligence)
* [A paper list of object detection using deep learning](https://github.com/hoya012/deep_learning_object_detection)
* [Scaling Uber’s Customer Support Ticket Assistant (COTA) System with Deep Learning.](https://eng.uber.com/cota-v2/)
* [Pandas Cheat Sheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)
* [DeepLearningAnimePapers](https://github.com/deeppomf/DeepLearningAnimePapers) - A list of papers and other resources on deep learning with anime style images.
* [**A list of all papers and resoureces on Semantic Segmentation**](https://github.com/tangzhenyu/SemanticSegmentation_DL)
* [Deep Learning in Medical Imaging and Medical Image Analysis](https://github.com/shawnyuen/DeepLearningInMedicalImagingAndMedicalImageAnalysis)

----
<a id="necessary-and-useful-tools"></a>
## Necessary and Useful Tools
* [List of scappers](https://github.com/cassidoo/scrapers) - Огромный список программ скрейперов помогающих извлекать данные из веб-сайтов. Это инструменты на всех языках программирования и несложные в освоении
* [Обработка текста с командной строки](https://github.com/dbohdan/structured-text-tools) -  Большая подборка инструментов позволяющих быстро обрабатывать CSV, JSON, XML и другие структурированные документы 
* [JKAN](https://jkan.io/) - Малоизвестный в России открытый движок JKAN для быстрой сборки статического портала открытых данных. Очень просто устроен, очень быстро разворачивается.
* [Kekyll on Haskell](https://jaspervdj.be/hakyll/) - быстрый движок подъема статистических страниц. Как Jekyll только на Хаскеле. Just for fun.
* [React Vizualization](https://github.com/bvaughn/react-virtualized) - визуализация на реакте. Зачем то. 
* [D3.js](https://d3js.org/) - нормальная визуализация с помошью нормального JS
* [PyTorch - Python + Nim](https://github.com/fragcolor-xyz/nimtorch) - компилируемый переписаный пайторч под ним
* [Lucid](https://github.com/tensorflow/lucid) - _Lucid is a collection of infrastructure and tools for research in neural network interpretability._ Фреймворк и набор тетрадок для анализа и визуализации нейросетей
* [AutoKeras](https://autokeras.com/)
* [auto-sklearn](http://automl.github.io/auto-sklearn/)
* [Research2vec](https://github.com/Santosh-Gupta/Research2Vec) - моделька для поиска похожих рисерч пейперов, можно юзать как рекомендашку
* [A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.](https://github.com/EpistasisLab/tpot)
* [Automated machine learning for structured data.](https://transmogrif.ai) - AutoML library for structured data written in Scala that runs on top of Apache Spark from SaleForce
* [Futuretools: An open source python framework for automated feature engineering](https://www.featuretools.com)
* [Entity Embedding for Categorical Data](https://github.com/entron/entity-embedding-rossmann)
* [Version Control System for Data Science!](https://dvc.org)


----
<a id="datasets"></a>
## Datasets
* [Some New Interesting Deep Learning Datasets for Data Scientists](http://blog.paralleldots.com/data-scientist/new-deep-learning-datasets-data-scientists/) - Список датасетов интересный
* [Cool Datasets](http://cooldatasets.com/) - сайт с датасетами клевыми
* [Целый сабреддит на реддите с датасетами и обсуждениями](https://www.reddit.com/r/datasets/)
* [Kaggle Recipe Ingredients Dataset](https://www.kaggle.com/kaggle/recipe-ingredients-dataset)
